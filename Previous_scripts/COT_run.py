import sys
import os
import json
import time
import traceback
from argparse import ArgumentParser
from dotenv import load_dotenv
import openai
from tqdm import tqdm

# Ensure src_CoT is in the path
sys.path.append('/home/student/ActiveRAG/src_CoT')

# Load environment variables from .env file
load_dotenv()

# Set OpenAI API key from environment variable
openai.api_key = os.getenv('API_KEY')


class CoTAgent:
    def __init__(self, model='gpt-4o-mini-2024-07-18'):
        self.message = []
        self.model = model

    def send_cot_message(self, question):
        """
        Send a message to OpenAI API to generate a response with chain of thought reasoning.
        """
        message = {
            'role': 'user',
            'content': f"Think step-by-step to answer the question.\n\nQuestion: {question}\nAnswer:"
        }
        self.message.append(message)

        try:
            ans = openai.ChatCompletion.create(
                model=self.model,
                messages=self.message,
                temperature=0.2,
                n=1
            )
            self.parse_message(ans)
            return ans
        except Exception as e:
            print(e)
            time.sleep(20)
            ans = openai.ChatCompletion.create(
                model=self.model,
                messages=self.message,
                temperature=0.2,
                n=1
            )
            self.parse_message(ans)
            return ans

    def parse_message(self, completion):
        content = completion['choices'][0]['message']['content']
        role = completion['choices'][0]['message']['role']
        record = {'role': role, 'content': content}
        self.message.append(record)
        return record

    def get_output(self):
        """
        Get the latest output generated by the model.
        """
        if len(self.message) == 0:
            raise ValueError("No messages found. Cannot get output.")
        return self.message[-1]['content']


class ChainOfThought:
    def __init__(self, agent: CoTAgent):
        self.agent = agent

    def run(self, question: str):
        """
        Run the Chain of Thought model to generate an answer.
        """
        # Send message to OpenAI to generate a response
        self.agent.send_cot_message(question)

        # Get and return the result
        return self.agent.get_output()


def run_cot_experiment(question: str):
    """
    Run the Chain of Thought experiment with the provided question.
    """
    # Initialize the CoT agent
    cot_agent = CoTAgent()

    # Set up the Chain of Thought with the agent
    chain_of_thought = ChainOfThought(cot_agent)

    # Run the Chain of Thought model
    result = chain_of_thought.run(question)

    print(f"Chain of Thought Result: {result}")
    return result


if __name__ == '__main__':
    parser = ArgumentParser()
    parser.add_argument('--dataset', required=True)
    parser.add_argument('--topk', type=int, required=True)
    args = parser.parse_args()

    dataset = args.dataset
    filename = f'data/data_{dataset}_sampled.jsonl'
    topk = args.topk

    cot_directory = f'cot/{dataset}/top{topk}/chain_of_thought'

    # Create directory for logs if it doesn't exist
    if not os.path.exists(cot_directory):
        os.makedirs(cot_directory)

    with open(filename, 'r', encoding='utf-8') as file:
        for i, line in tqdm(enumerate(file)):
            try:
                data = json.loads(line)
                question = data['question']

                # Run Chain of Thought Experiment
                cot_result = run_cot_experiment(question)

                # Save the result
                with open(f'{cot_directory}/{dataset}_idx_{i}.json', 'w', encoding='utf-8') as vr_file:
                    json.dump({'question': question, 'chain_of_thought_result': cot_result}, vr_file)

            except Exception as e:
                current_time = time.strftime("%Y-%m-%d %H:%M:%S")
                print(f"Error at index {i} - {current_time}: {e}")
                traceback.print_exc()
                break
